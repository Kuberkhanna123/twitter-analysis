{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter Analysis",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf2kRzcGvsJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import twitter\n",
        "\n",
        "# initialize api instance\n",
        "twitter_api = twitter.Api(consumer_key='YOUR_CONSUMER_KEY',\n",
        "                        consumer_secret='YOUR_CONSUMER_SECRET',\n",
        "                        access_token_key='YOUR_ACCESS_TOKEN_KEY',\n",
        "                        access_token_secret='YOUR_ACCESS_TOKEN_SECRET')\n",
        "\n",
        "# test authentication\n",
        "print(twitter_api.VerifyCredentials())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDAE03FPv1vX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildTestSet(search_keyword):\n",
        "    try:\n",
        "        tweets_fetched = twitter_api.GetSearch(search_keyword, count = 100)\n",
        "        \n",
        "        print(\"Fetched \" + str(len(tweets_fetched)) + \" tweets for the term \" + search_keyword)\n",
        "        \n",
        "        return [{\"text\":status.text, \"label\":None} for status in tweets_fetched]\n",
        "    except:\n",
        "        print(\"Unfortunately, something went wrong..\")\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhpbiOtCv52C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "search_term = input(\"Enter a search keyword:\")\n",
        "testDataSet = buildTestSet(search_term)\n",
        "\n",
        "print(testDataSet[0:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXDVW9Fiv893",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buidTrainingSet(corpusFile, tweetDataFile):\n",
        "    import csv\n",
        "    import time\n",
        "    \n",
        "    corpus = []\n",
        "    \n",
        "    with open(corpusFile,'rb') as csvfile:\n",
        "        lineReader = csv.reader(csvfile,delimiter=',', quotechar=\"\\\"\")\n",
        "        for row in lineReader:\n",
        "            corpus.append({\"tweet_id\":row[2], \"label\":row[1], \"topic\":row[0]})\n",
        "            \n",
        "    rate_limit = 180\n",
        "    sleep_time = 900/180\n",
        "    \n",
        "    trainingDataSet = []\n",
        "    \n",
        "    for tweet in corpus:\n",
        "        try:\n",
        "            status = twitter_api.GetStatus(tweet[\"tweet_id\"])\n",
        "            print(\"Tweet fetched\" + status.text)\n",
        "            tweet[\"text\"] = status.text\n",
        "            trainingDataSet.append(tweet)\n",
        "            time.sleep(sleep_time) \n",
        "        except: \n",
        "            continue\n",
        "    # now we write them to the empty CSV file\n",
        "    with open(tweetDataFile,'wb') as csvfile:\n",
        "        linewriter = csv.writer(csvfile,delimiter=',',quotechar=\"\\\"\")\n",
        "        for tweet in trainingDataSet:\n",
        "            try:\n",
        "                linewriter.writerow([tweet[\"tweet_id\"], tweet[\"text\"], tweet[\"label\"], tweet[\"topic\"]])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return trainingDataSet"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}